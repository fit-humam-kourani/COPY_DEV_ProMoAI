Model,Total Average,Up_to_13,Higher
ground truth,0.98422327,0.983788796,0.985961166
claude-3-5-sonnet-20240620,0.93134829,0.933615794,0.922278275
o1-preview,0.918281977,0.915676748,0.928702892
o1-mini,0.90874262,0.935035505,0.803571082
gemini-1.5-pro-002-IT3,0.865330468,0.868972091,0.850763977
Llama-3.1-405B-Instruct,0.856924494,0.878476829,0.770715154
Llama-3.1-Nemotron-70B-Instruct,0.833543322,0.863743521,0.712742525
Llama-3.2-90B-Vision-Instruct,0.803826375,0.812840979,0.767767961
Qwen2.5-72B-Instruct,0.802630484,0.818493582,0.739178089
mistral-large-2407,0.7758067,0.827456854,0.569206086
gpt-4,0.755682246,0.776011067,0.674366962
gpt-4o,0.755074559,0.770603378,0.692959285
gpt-4o-mini,0.736372416,0.738926427,0.726156373
WizardLM-2-8x22B,0.732876181,0.771339417,0.579023236
codestral-2405,0.731909419,0.771344737,0.574168148
gemini-1.5-flash-002,0.7268155,0.738730648,0.679154905
open-mixtral-8x22b,0.720249771,0.774831541,0.501922692
,,,
,0.803463426,0.824756195,0.718292353
